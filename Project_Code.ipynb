{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kATMRMtLl4sl"
      },
      "outputs": [],
      "source": [
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Select your kaggle.json file\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "vAZiWJR4l9Ht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l #is used to display the contents of a directory in a detailed (long) list format"
      ],
      "metadata": {
        "id": "Xujvtb1OmAUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv \"Kaggle.json\" kaggle.json #Renames or moves the file Kaggle.json to kaggle.json."
      ],
      "metadata": {
        "id": "U9iRS5s7mCSl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle #Creates the directory ~/.kaggle (in the user's home directory). If the directory already exists, no error occurs.\n",
        "# It creates parent directories if needed.\n",
        "\n",
        "!mv kaggle.json ~/.kaggle/ # Purpose: Moves the kaggle.json file into the .kaggle directory under the user's home folder (~/.kaggle).\n"
      ],
      "metadata": {
        "id": "ANnYw7j2mEPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json #s used to set file permissions for the kaggle.json file located in the .kaggle directory under the user's home folder."
      ],
      "metadata": {
        "id": "PbeGq-7WmGhF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia #Downloads the specified dataset from Kaggle.Downloads a ZIP file containing the dataset into the current working directory.\n"
      ],
      "metadata": {
        "id": "3dm1ZtbMmH4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip chest-xray-pneumonia.zip -d /content/chest_xray #Extracts the downloaded dataset into a specific directory. Extracts all files and folders from chest-xray-pneumonia.zip into /content/chest_xray."
      ],
      "metadata": {
        "id": "L8RUPPcQmJa1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os #Imports the os module, which provides functions for interacting with the file system.\n",
        "for dirname, _, filenames in os.walk('/content/chest_xray'):\n",
        "    for filename in filenames: #Loops through the list of filenames in each directory.\n",
        "        print(os.path.join(dirname, filename)) #Outputs the full path of each file to the console."
      ],
      "metadata": {
        "id": "ipab_OcpmKpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt # Used for creating graphs and visualizations (e.g., line plots, histograms, etc.).\n",
        "import seaborn as sns\n",
        "import cv2 #Used to read, preprocess, and manipulate images in deep learning tasks.\n",
        "import tensorflow as tf #Provides tools to build and train machine learning models.\n",
        "from tensorflow.keras.models import Sequential #Sequential API allows for a linear stack of layers to define a model.\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, BatchNormalization\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator #Used for real-time data augmentation, which generates batches of image data with transformations like rotation, zoom, or flipping\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau #Callback function that reduces the learning rate when a metric (like validation loss) has stopped improving.\n",
        "from sklearn.model_selection import train_test_split #Splits datasets into training and test subsets.\n",
        "from sklearn.metrics import classification_report, confusion_matrix # Provides precision, recall, F1-score, and support for classification models.\n",
        "#valuates the performance of classification models by showing true vs. predicted classes."
      ],
      "metadata": {
        "id": "VZaO8qhEmMTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This script is designed to load and preprocess image data for a classification task (e.g., detecting pneumonia). The images are resized, reshaped, and labeled for model training, testing, and validation.\n",
        "labels = ['PNEUMONIA', 'NORMAL'] #Specifies the two classes in the dataset.\n",
        "img_size = 150 #The target size (height and width) for resizing images.\n",
        "\n",
        "def get_training_data(data_dir): #processes  all images in a given directory (data_dir) and prepares them for model training or evaluation.\n",
        "    data = [] #Initializes an empty list to store image data and corresponding labels.\n",
        "    for label in labels:\n",
        "        path = os.path.join(data_dir, label) #Constructs the directory path for the current label.\n",
        "        class_num = labels.index(label) #Assigns a numeric label to the class (0 for PNEUMONIA, 1 for NORMAL).\n",
        "        for img in os.listdir(path):\n",
        "            try:\n",
        "                # Read the image as grayscale\n",
        "                img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE) #Reads the image in grayscale using OpenCV\n",
        "                # Resize the image\n",
        "                resized_arr = cv2.resize(img_arr, (img_size, img_size))\n",
        "                # Reshape the image array to include a channel dimension\n",
        "                resized_arr = resized_arr.reshape((img_size, img_size, 1))\n",
        "                # Append the resized image and class number to the data list\n",
        "                data.append([resized_arr, class_num])\n",
        "            except Exception as e:\n",
        "                print(e)\n",
        "    # Convert the data list to a NumPy array with a consistent dtype\n",
        "    return np.array(data, dtype=object)\n",
        "\n",
        "train = get_training_data('/content/chest_xray/chest_xray/chest_xray/train')\n",
        "test = get_training_data('/content/chest_xray/chest_xray/chest_xray/test')\n",
        "val = get_training_data('/content/chest_xray/chest_xray/chest_xray/val')"
      ],
      "metadata": {
        "id": "Qbx9HAjomN3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content"
      ],
      "metadata": {
        "id": "YUamCTHmmPP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/chest_xray\n",
        "!ls /content/chest_xray/train\n",
        "!ls /content/chest_xray/train/PNEUMONIA"
      ],
      "metadata": {
        "id": "aB2p2em3mRGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -R /content/chest_xray"
      ],
      "metadata": {
        "id": "QBb8P2WTmRjW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This block processes the data prepared earlier (train, test, and val) into separate\n",
        "# feature and label arrays, normalizes the images, and reshapes them for input into a machine learning or deep learning model\n",
        "x_train, y_train = [], [] #Initializes empty lists for features (x_*) and labels (y_*) for the training, testing, and validation sets.\n",
        "x_test, y_test = [], []\n",
        "x_val, y_val = [], []\n",
        "\n",
        "for feature, label in train: #For each tuple (feature, label) in the dataset:\n",
        "# x_*: Appends the image array (features).\n",
        "# y_*: Appends the corresponding label.\n",
        "    x_train.append(feature)\n",
        "    y_train.append(label)\n",
        "\n",
        "for feature, label in test:\n",
        "    x_test.append(feature)\n",
        "    y_test.append(label)\n",
        "\n",
        "for feature, label in val:\n",
        "    x_val.append(feature)\n",
        "    y_val.append(label)\n",
        "\n",
        "# Normalize data\n",
        "x_train = np.array(x_train) / 255.0\n",
        "x_test = np.array(x_test) / 255.0\n",
        "x_val = np.array(x_val) / 255.0\n",
        "\n",
        "# Reshape data for the model\n",
        "x_train = x_train.reshape(-1, img_size, img_size, 1)\n",
        "x_test = x_test.reshape(-1, img_size, img_size, 1)\n",
        "x_val = x_val.reshape(-1, img_size, img_size, 1)\n",
        "\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)\n",
        "y_val = np.array(y_val)\n"
      ],
      "metadata": {
        "id": "74X9EaAImTy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This snippet uses the ImageDataGenerator class from Keras to perform real-time data augmentation on the training data.\n",
        "# Data augmentation generates transformed versions of the existing images, which helps improve the model's ability to generalize.\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=30,\n",
        "    zoom_range=0.2,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "datagen.fit(x_train)\n"
      ],
      "metadata": {
        "id": "NXLIniDnmVW3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This script defines and compiles a Convolutional Neural Network (CNN) for binary classification, suitable for detecting conditions like pneumonia in grayscale chest X-ray images.\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3,3), activation='relu', input_shape=(img_size, img_size, 1)), #Extract spatial features from images using filters.\n",
        "    BatchNormalization(), #Normalizes the output of a layer to stabilize and accelerate training.\n",
        "    MaxPool2D(2,2), #Purpose: Reduces the spatial dimensions of feature maps, retaining only the most important features.\n",
        "    Conv2D(64, (3,3), activation='relu'),\n",
        "    Dropout(0.1), # Randomly \"drops\" a fraction of neurons during training to prevent overfitting.\n",
        "    BatchNormalization(),\n",
        "    MaxPool2D(2,2),\n",
        "    Conv2D(64, (3,3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPool2D(2,2),\n",
        "    Conv2D(128, (3,3), activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    BatchNormalization(),\n",
        "    MaxPool2D(2,2),\n",
        "    Conv2D(256, (3,3), activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    BatchNormalization(),\n",
        "    MaxPool2D(2,2),\n",
        "    Flatten(), #Flattens the 2D feature maps into a 1D vector to connect to fully connected layers.\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "dQ62p2f5mW7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This callback adjusts the learning rate during training when the model's performance plateaus, specifically when the validation accuracy doesn't improve for a set number of epochs.\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience=2, factor=0.3, min_lr=0.000001)\n"
      ],
      "metadata": {
        "id": "kQWOb5dtmXfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This line starts the training process of the model using the augmented data from the ImageDataGenerator and applies the learning rate reduction callback to adjust the learning rate during training based on the validation accuracy.\n",
        "history = model.fit(\n",
        "    datagen.flow(x_train, y_train, batch_size=32),\n",
        "    epochs=12,\n",
        "    validation_data=(x_val, y_val),\n",
        "    callbacks=[learning_rate_reduction]\n",
        ")\n"
      ],
      "metadata": {
        "id": "sODu2MeRmYmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(x_test, y_test)\n",
        "print(f\"Model Test Loss: {loss}\")\n",
        "print(f\"Model Test Accuracy: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "id": "ZDvhkZVDmZtf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = [i for i in range(12)]\n",
        "fig , ax = plt.subplots(1,2) #Creates a 1x2 grid of subplots, meaning two plots side by side in the same figure.\n",
        "train_acc = history.history['accuracy']\n",
        "train_loss = history.history['loss']\n",
        "val_acc = history.history['val_accuracy']\n",
        "val_loss = history.history['val_loss']\n",
        "fig.set_size_inches(20,10)\n",
        "\n",
        "# First Plot: Training & Validation Accuracy\n",
        "\n",
        "ax[0].plot(epochs , train_acc , 'go-' , label = 'Training Accuracy')\n",
        "ax[0].plot(epochs , val_acc , 'ro-' , label = 'Validation Accuracy')\n",
        "ax[0].set_title('Training & Validation Accuracy')\n",
        "ax[0].legend()\n",
        "ax[0].set_xlabel(\"Epochs\")\n",
        "ax[0].set_ylabel(\"Accuracy\")\n",
        "\n",
        "# Second Plot: Training & Validation Loss\n",
        "\n",
        "ax[1].plot(epochs , train_loss , 'g-o' , label = 'Training Loss')\n",
        "ax[1].plot(epochs , val_loss , 'r-o' , label = 'Validation Loss')\n",
        "ax[1].set_title('Testing Accuracy & Loss')\n",
        "ax[1].legend()\n",
        "ax[1].set_xlabel(\"Epochs\")\n",
        "ax[1].set_ylabel(\"Training & Validation Loss\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "d0E5C2g8mbe4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This code is used to obtain predictions from the trained model, convert those predictions into class labels (0 or 1), and display the first 15 predictions. Here's a step-by-step breakdown\n",
        "# Get predictions as probabilities\n",
        "predictions = model.predict(x_test)\n",
        "\n",
        "# Convert probabilities to class labels (0 or 1) by applying a threshold\n",
        "predictions = (predictions > 0.5).astype(\"int32\")\n",
        "\n",
        "# Flatten the array for easier readability\n",
        "predictions = predictions.reshape(1, -1)[0]\n",
        "\n",
        "# Display the first 15 predictions\n",
        "predictions[:15]\n"
      ],
      "metadata": {
        "id": "oaZgHeOVmdCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, predictions, target_names = ['Pneumonia (Class 0)','Normal (Class 1)']))"
      ],
      "metadata": {
        "id": "xncnx18ZmfDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test,predictions)\n",
        "cm"
      ],
      "metadata": {
        "id": "lIvR2Uximgh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = pd.DataFrame(cm , index = ['0','1'] , columns = ['0','1'])"
      ],
      "metadata": {
        "id": "umN9jCo6mhQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (10,10))\n",
        "sns.heatmap(cm,cmap= \"Blues\", linecolor = 'black' , linewidth = 1 , annot = True, fmt='',xticklabels = labels,yticklabels = labels)"
      ],
      "metadata": {
        "id": "IW_REvyEmi9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct = np.nonzero(predictions == y_test)[0]\n",
        "incorrect = np.nonzero(predictions != y_test)[0]"
      ],
      "metadata": {
        "id": "eVUgBBV_mjlo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "for c in correct[:6]:\n",
        "    plt.subplot(3,2,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.imshow(x_test[c].reshape(150,150), cmap=\"gray\", interpolation='none')\n",
        "    plt.title(\"Predicted Class {},Actual Class {}\".format(predictions[c], y_test[c]))\n",
        "    plt.tight_layout()\n",
        "    i += 1"
      ],
      "metadata": {
        "id": "vktyvPoNmlPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === USER UPLOADED IMAGE PREDICTION ===\n",
        "from google.colab import files\n",
        "\n",
        "print(\"\\n\\n=== Upload a chest X-ray image to predict ===\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "for img_name in uploaded.keys():\n",
        "    img_path = img_name\n",
        "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "    img = cv2.resize(img, (img_size, img_size))\n",
        "    img = img.reshape(1, img_size, img_size, 1) / 255.0\n",
        "    prediction = model.predict(img)\n",
        "    result = \"NORMAL\" if prediction[0][0] < 0.5 else \"PNEUMONIA\"\n",
        "    plt.imshow(cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB))\n",
        "    plt.title(f\"Prediction: {result}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "    print(f\"\\nThe uploaded X-ray image is predicted to be: **{result}**\")"
      ],
      "metadata": {
        "id": "z2pU4jSwmr_p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}